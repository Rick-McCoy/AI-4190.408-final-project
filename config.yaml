experiment_name: "celeba_vae_experiment"
output_base_dir: "runs_vae"

dataset:
  name: "CelebA"
  root_dir: "./data"
  image_size: 64
  center_crop_size: 140
  batch_size: 256
  num_workers: 4
  pin_memory: true
  split_ratios:
    train: 0.8
    val: 0.1
  celeba_use_predefined_splits: true

model:
  type: "ConvolutionalVAE"
  latent_dim: 128
  encoder_channels: [3, 32, 64, 128, 256]
  decoder_channels: [256, 128, 64, 32, 3]
  use_batch_norm: true
  activation: "relu"

training:
  epochs: 50
  learning_rate: 0.0002
  optimizer: "Adam"
  adam_betas: [0.5, 0.999]
  weight_decay: 0.0
  kl_beta: 1.0
  kl_anneal_epochs: 10
  scheduler:
    name: null
    # ReduceLROnPlateau specific:
    # factor: 0.1
    # patience: 10
    # StepLR specific:
    # step_size: 30
    # gamma: 0.1
  gradient_clip_val: null

logging:
  log_level: "INFO"
  tensorboard_log_freq_images: 1
  console_log_freq_metrics: 100

visualization:
  num_reconstructions: 16
  num_generated_samples: 16
  num_interpolation_steps: 8
  num_tsne_embeddings: 1000
  tsne_target_attribute: "Smiling"

seed: 42
