experiment_name: "celeba_vae_experiment"
output_base_dir: "runs_vae" # Base directory for all outputs

# --- Dataset Configuration ---
dataset:
  name: "CelebA" # Or others if you extend later
  root_dir: "./data" # Where to download/store CelebA
  image_size: 128 # e.g., 64, 128
  center_crop_size: 140 # Size for center cropping before resizing (e.g., 140 for 178 CelebA images)
  batch_size: 256
  num_workers: 4
  pin_memory: true
  split_ratios: # Used if dataset doesn't have predefined splits or to override
    train: 0.8
    val: 0.1
    # test split will be 1.0 - train - val
  celeba_use_predefined_splits: true # If true, ignores split_ratios for CelebA

# --- Model Configuration ---
model:
  type: "ConvolutionalVAE"
  latent_dim: 128 # Dimensionality of the latent space
  # For a simple CNN VAE, define channels. Example for 64x64 input:
  # Encoder: 3 -> 32 -> 64 -> 128 -> 256 (followed by flatten & FCs to latent_dim)
  # Decoder: latent_dim -> FCs to 256 * 4 * 4 -> Reshape -> 256 -> 128 -> 64 -> 32 -> 3
  encoder_channels: [3, 32, 64, 128, 256, 512] # Input channels (3 for RGB) followed by conv layer output channels
  decoder_channels: [512, 256, 128, 64, 32, 3] # Channels for ConvTranspose layers, ending in output channels (3 for RGB)
  use_batch_norm: true
  activation: "relu" # "relu", "leaky_relu"

# --- Training Configuration ---
training:
  epochs: 50
  learning_rate: 0.0002
  optimizer: "Adam" # Adam, SGD, etc.
  adam_betas: [0.5, 0.999] # Common for GANs/VAEs
  weight_decay: 0.0
  kl_beta: 1.0 # Weight for KL divergence term (can be annealed)
  kl_anneal_epochs: 10 # Number of epochs to anneal beta from 0 to kl_beta
  scheduler: # Optional
    name: null # e.g., "ReduceLROnPlateau" or "StepLR"
    # ReduceLROnPlateau specific:
    # factor: 0.1
    # patience: 10
    # StepLR specific:
    # step_size: 30
    # gamma: 0.1
  gradient_clip_val: null # e.g., 1.0 if you want gradient clipping

# --- Logging & Visualization ---
logging:
  log_level: "INFO" # DEBUG, INFO, WARNING, ERROR
  tensorboard_log_freq_images: 1 # Log images to TensorBoard every N epochs
  console_log_freq_metrics: 100 # Log metrics to console every N batches (if not using tqdm for batches)

visualization:
  num_reconstructions: 16 # Number of images for reconstruction visualization
  num_generated_samples: 16 # Number of generated samples
  num_interpolation_steps: 8 # Number of steps between two images for interpolation
  # For t-SNE/UMAP visualization on TensorBoard embeddings projector
  num_tsne_embeddings: 1000 # Number of validation samples to use for latent space embedding
  tsne_target_attribute: "Smiling" # CelebA attribute to color_by (e.g., "Smiling", "Male", "Eyeglasses"). Null for no specific attribute.

# --- Reproducibility ---
seed: 42
